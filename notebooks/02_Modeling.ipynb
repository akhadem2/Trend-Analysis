{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b45c00f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.metrics import classification_report, confusion_matrix, f1_score, accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score\n",
    "from imblearn.pipeline import Pipeline\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from xgboost import XGBClassifier  # or GradientBoostingClassifier if you prefer sklearn-only\n",
    "import shap, seaborn as sns, matplotlib.pyplot as plt\n",
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "\n",
    "df = pd.read_csv(\"../data/youtube_shorts_tiktok_trends_2025.csv_ML.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d08b176",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sentiment from raw titles (aligns row-for-row with the _ML file)\n",
    "sia = SentimentIntensityAnalyzer()\n",
    "df_raw = pd.read_csv(\"../data/youtube_shorts_tiktok_trends_2025.csv\", usecols=[\"title\"])\n",
    "df[\"title_sentiment\"] = df_raw[\"title\"].fillna(\"\").apply(lambda t: sia.polarity_scores(t)[\"compound\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f73707ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../src\")\n",
    "\n",
    "from preprocess import map_labels, clean_features, get_feature_matrix\n",
    "from model_utils import rate_video\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1332011a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_country = pd.read_csv(\"../data/country_platform_summary_2025.csv\")\n",
    "df_country.head()\n",
    "\n",
    "df_country.rename(columns={'country': 'region'}, inplace=True)\n",
    "\n",
    "df_enriched = df.merge(\n",
    "    df_country[['region', 'platform', 'median_er', 'avg_velocity', 'avg_engagement_per_1k']],\n",
    "    on=['region', 'platform'],\n",
    "    how='left'\n",
    ")\n",
    "# Compute region+platform \"strength\" from your own ML data\n",
    "region_platform_strength = (\n",
    "    df.groupby(['region', 'platform'])\n",
    "      .agg({\n",
    "          'views_per_day': 'mean',\n",
    "          'like_rate': 'mean',\n",
    "          'share_rate': 'mean',\n",
    "          'rel_like': 'mean',\n",
    "          'rel_share': 'mean'\n",
    "      })\n",
    "      .reset_index()\n",
    "      .rename(columns={\n",
    "          'views_per_day': 'region_platform_avg_views_per_day',\n",
    "          'like_rate': 'region_platform_avg_like_rate',\n",
    "          'share_rate': 'region_platform_avg_share_rate',\n",
    "          'rel_like': 'region_platform_avg_rel_like',\n",
    "          'rel_share': 'region_platform_avg_rel_share'\n",
    "      })\n",
    ")\n",
    "\n",
    "region_platform_strength.head()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5863fe5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = map_labels(df)\n",
    "df['trend_bucket'].value_counts()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8ff355c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_enriched = df.merge(\n",
    "    region_platform_strength,\n",
    "    on=['region', 'platform'],\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "df_enriched[['region', 'platform',\n",
    "             'region_platform_avg_views_per_day',\n",
    "             'region_platform_avg_like_rate']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2763517a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "import re, collections\n",
    "import re, json,os\n",
    "\n",
    "def extract_hashtags(text):\n",
    "    return re.findall(r\"#\\w+\", text.lower()) if isinstance(text, str) else []\n",
    "\n",
    "# Load the top tags you just saved\n",
    "top_tags_path = \"../models/top_trending_hashtags.json\"\n",
    "top_tags = set(json.load(open(top_tags_path))) if os.path.exists(top_tags_path) else set()\n",
    "\n",
    "try:\n",
    "    # Use the raw file (it has hashtags); assumes same row order as df_enriched/df\n",
    "    df_raw_tags = pd.read_csv(\"../data/youtube_shorts_tiktok_trends_2025.csv\", usecols=[\"hashtag\"])\n",
    "    hashtag_lists = df_raw_tags[\"hashtag\"].fillna(\"\").apply(extract_hashtags)\n",
    "    hits = hashtag_lists.apply(lambda hs: sum(h in top_tags for h in hs))\n",
    "    counts = hashtag_lists.apply(len)\n",
    "    df_enriched[\"trending_hashtag_hits\"] = hits\n",
    "    df_enriched[\"trending_hashtag_ratio\"] = hits / (counts + 1e-6)\n",
    "except Exception as e:\n",
    "    print(\"Hashtag column not found; defaulting to zeros:\", e)\n",
    "    df_enriched[\"trending_hashtag_hits\"] = 0\n",
    "    df_enriched[\"trending_hashtag_ratio\"] = 0\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "features = [\n",
    "    'title_len', 'text_richness',\n",
    "    'like_rate', 'comment_rate', 'share_rate',\n",
    "    'views_per_day', 'likes_per_day',\n",
    "    'rel_like', 'rel_share', 'rel_combo',\n",
    "    'like_hashtag_interaction', 'share_hashtag_interaction',\n",
    "    'platform_cat', 'region_cat', 'language_cat', \n",
    "    'category_cat', 'traffic_source_cat',\n",
    "    'device_brand_cat', 'creator_tier_cat',\n",
    "    'richness_traffic_interaction', 'weekend_hashtag_boost',\n",
    "        'region_platform_avg_views_per_day',\n",
    "    'region_platform_avg_like_rate',\n",
    "    'region_platform_avg_share_rate',\n",
    "    'region_platform_avg_rel_like',\n",
    "    'region_platform_avg_rel_share',\n",
    "    \"title_sentiment\",\n",
    "    'trending_hashtag_hits',     \n",
    "    'trending_hashtag_ratio',   \n",
    "\n",
    "]\n",
    "features = list(dict.fromkeys(features))  # remove dupes\n",
    "\n",
    "df_clean = clean_features(df_enriched, features)\n",
    "X, y = get_feature_matrix(df_clean, features)\n",
    "\n",
    "# encode labels\n",
    "le = LabelEncoder()\n",
    "y_enc = le.fit_transform(y)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y_enc, test_size=0.2, random_state=42, stratify=y_enc\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b187e0b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "balanced_samples = (\n",
    "    df_clean\n",
    "    .groupby('trend_bucket', group_keys=False)\n",
    "    .apply(lambda g: g.sample(min(3, len(g)), random_state=42))\n",
    ")\n",
    "\n",
    "balanced_samples[['trend_bucket']].head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78721746",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix, classification_report\n",
    "\n",
    "xgb = XGBClassifier(\n",
    "    n_estimators=400,\n",
    "    learning_rate=0.05,\n",
    "    max_depth=6,\n",
    "    subsample=0.9,\n",
    "    colsample_bytree=0.9,\n",
    "    objective=\"multi:softprob\",\n",
    "    eval_metric=\"mlogloss\",\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    (\"smote\", SMOTE(random_state=42)),\n",
    "    (\"model\", xgb)\n",
    "])\n",
    "\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "cv_scores = cross_val_score(pipeline, X, y_enc, cv=cv, scoring=\"f1_macro\")\n",
    "print(\"CV macro F1 (mean ± std):\", cv_scores.mean(), cv_scores.std())\n",
    "\n",
    "# Fit\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Keep label names on the pipeline (custom attrs are allowed)\n",
    "pipeline.label_encoder_ = le\n",
    "pipeline.class_labels_ = le.classes_\n",
    "\n",
    "# Metrics (decode ints back to strings)\n",
    "preds_int = pipeline.predict(X_test)\n",
    "preds = le.inverse_transform(preds_int)\n",
    "y_test_labels = le.inverse_transform(y_test)\n",
    "\n",
    "print(\"Holdout Accuracy:\", accuracy_score(y_test_labels, preds))\n",
    "print(\"Holdout Macro F1:\", f1_score(y_test_labels, preds, average=\"macro\"))\n",
    "print(classification_report(y_test_labels, preds, target_names=le.classes_))\n",
    "\n",
    "\n",
    "model = pipeline  # for saving\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2fc7d2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_bg = X_train.sample(200, random_state=42)\n",
    "X_explain = X_test.sample(100, random_state=42)\n",
    "\n",
    "explainer = shap.Explainer(lambda data: model.predict_proba(data), X_bg, feature_names=features)\n",
    "shap_values = explainer(X_explain)\n",
    "classes = list(getattr(model, \"class_labels_\", model.named_steps[\"model\"].classes_))\n",
    "cls_idx = classes.index(\"trending\") if \"trending\" in classes else 0\n",
    "shap.plots.beeswarm(shap_values[:, :, cls_idx], max_display=10)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34ccc83b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "rf = RandomForestClassifier(n_estimators=400, random_state=42)\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "pred_rf = rf.predict(X_test)\n",
    "\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(y_test, pred_rf))\n",
    "print(\"Macro F1:\", f1_score(y_test, pred_rf, average='macro'))\n",
    "print(confusion_matrix(y_test, pred_rf))\n",
    "print(classification_report(y_test, pred_rf))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39ac76da",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4fd136c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold, cross_val_score\n",
    "\n",
    "# CV for RandomForest (use your fitted rf)\n",
    "cv_rf = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n",
    "cv_scores_rf = cross_val_score(rf, X, y, cv=cv_rf, scoring=\"f1_macro\", n_jobs=1)  # <- force single process\n",
    "print(\"RF CV macro F1 (mean ± std):\", cv_scores_rf.mean(), cv_scores_rf.std())\n",
    "\n",
    "# Holdout metrics for RandomForest\n",
    "pred_rf_holdout = rf.predict(X_test)\n",
    "print(\"\\nRandom Forest Holdout Performance:\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, pred_rf_holdout))\n",
    "print(\"Macro F1:\", f1_score(y_test, pred_rf_holdout, average='macro'))\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(confusion_matrix(y_test, pred_rf_holdout))\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, pred_rf_holdout))\n",
    "\n",
    "# CV for XGB+SMOTE (use your fitted pipeline / cv already defined as cv)\n",
    "cv_scores_xgb = cv_scores  # if you already computed; otherwise:\n",
    "# cv_scores_xgb = cross_val_score(pipeline, X, y_enc, cv=cv, scoring=\"f1_macro\", n_jobs=-1)\n",
    "print(\"\\nXGB+SMOTE CV macro F1 (mean ± std):\", cv_scores_xgb.mean(), cv_scores_xgb.std())\n",
    "\n",
    "# Holdout metrics for XGB+SMOTE (already computed in cell 10, showing again for comparison)\n",
    "print(\"\\nXGB+SMOTE Holdout Performance:\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test_labels, preds))\n",
    "print(\"Macro F1:\", f1_score(y_test_labels, preds, average=\"macro\"))\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(confusion_matrix(y_test_labels, preds))\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test_labels, preds, target_names=le.classes_))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9800fe7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "log_reg = LogisticRegression(max_iter=3000, multi_class=\"multinomial\")\n",
    "log_reg.fit(X_train, y_train)\n",
    "\n",
    "# CV for logistic regression\n",
    "cv_log = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n",
    "cv_scores_log = cross_val_score(log_reg, X, y, cv=cv_log, scoring=\"f1_macro\", n_jobs=1)\n",
    "print(\"LogReg CV macro F1 (mean ± std):\", cv_scores_log.mean(), cv_scores_log.std())\n",
    "\n",
    "# Holdout metrics for log_reg\n",
    "pred_log = log_reg.predict(X_test)\n",
    "print(\"\\nLogistic Regression Holdout Performance:\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, pred_log))\n",
    "print(\"Macro F1:\", f1_score(y_test, pred_log, average=\"macro\"))\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(confusion_matrix(y_test, pred_log))\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, pred_log))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cad89486",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score\n",
    "\n",
    "# Build a small MLP with scaling\n",
    "mlp = Pipeline([\n",
    "    (\"scaler\", StandardScaler()),\n",
    "    (\"clf\", MLPClassifier(\n",
    "        hidden_layer_sizes=(64, 32),\n",
    "        activation=\"relu\",\n",
    "        alpha=1e-4,\n",
    "        max_iter=500,\n",
    "        random_state=42\n",
    "    )),\n",
    "])\n",
    "\n",
    "# Use encoded labels if you're encoding (y_enc); otherwise y\n",
    "y_for_fit = y_enc if \"y_enc\" in globals() else y\n",
    "X_for_fit = X\n",
    "\n",
    "# CV (keep n_jobs=1 if you've had joblib issues)\n",
    "cv_mlp = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n",
    "cv_scores_mlp = cross_val_score(mlp, X_for_fit, y_for_fit, cv=cv_mlp, scoring=\"f1_macro\", n_jobs=1)\n",
    "print(\"MLP CV macro F1 (mean ± std):\", cv_scores_mlp.mean(), cv_scores_mlp.std())\n",
    "\n",
    "# Fit and holdout metrics\n",
    "mlp.fit(X_train, y_train if \"y_enc\" not in globals() else y_train)\n",
    "pred_mlp = mlp.predict(X_test)\n",
    "print(\"\\nMLP (Neural Network) Holdout Performance:\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, pred_mlp))\n",
    "print(\"Macro F1:\", f1_score(y_test, pred_mlp, average=\"macro\"))\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(confusion_matrix(y_test, pred_mlp))\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, pred_mlp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eadd655",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_rows = df_clean.sample(5, random_state=42)  # or remove if not needed\n",
    "\n",
    "test_videos = [\n",
    "    row[features].to_dict()\n",
    "    for _, row in balanced_samples.iterrows()\n",
    "]\n",
    "\n",
    "for _, row in sample_rows.iterrows():\n",
    "    test_videos.append(row[features].to_dict())\n",
    "\n",
    "for i, video in enumerate(test_videos):\n",
    "    print(f\"\\n--- Test Video {i+1} ---\")\n",
    "    display(pd.DataFrame(video, index=[0]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de312b37",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "platform_map = df[['platform', 'platform_cat']].drop_duplicates().set_index('platform_cat')['platform'].to_dict()\n",
    "\n",
    "region_map = df[['region', 'region_cat']].drop_duplicates().set_index('region_cat')['region'].to_dict()\n",
    "\n",
    "for i, video in enumerate(test_videos):\n",
    "    pred, score = rate_video(video, model)\n",
    "    score_text = f\"{score:.2f}/100\" if score is not None else \"n/a\"\n",
    "    print(f\"Video {i+1}:\")\n",
    "    print(f\"  Predicted Category: {pred}\")\n",
    "    print(f\"  Trending Score: {score_text}\")\n",
    "\n",
    "    \n",
    "    print(f\"Platform: {platform_map[video['platform_cat']]}\")\n",
    "    print(f\"Region: {region_map[video['region_cat']]}\")\n",
    "\n",
    "    \n",
    "    if score > 60:\n",
    "        print(\"  Interpretation: This video is highly likely to trend.\")\n",
    "    elif score > 20:\n",
    "        print(\"  Interpretation: Decent performance but not strong enough to trend.\")\n",
    "    else:\n",
    "        print(\"  Interpretation: Weak performance relative to region/platform norms.\")\n",
    "    \n",
    "    print()\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05eca00e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json, os\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "def eval_model(clf, X_test, y_test, le=None):\n",
    "    preds = clf.predict(X_test)\n",
    "    y_true = y_test\n",
    "    if le is not None:\n",
    "        preds = le.inverse_transform(preds)\n",
    "        y_true = le.inverse_transform(y_test)\n",
    "    return {\n",
    "        \"acc\": accuracy_score(y_true, preds),\n",
    "        \"f1_macro\": f1_score(y_true, preds, average=\"macro\"),\n",
    "    }\n",
    "\n",
    "results = {}\n",
    "\n",
    "if \"log_reg\" in globals():\n",
    "    results[\"log_reg\"] = {\n",
    "        \"cv_f1_mean\": cv_scores_log.mean(),\n",
    "        \"cv_f1_std\": cv_scores_log.std(),\n",
    "        **eval_model(log_reg, X_test, y_test, le if \"le\" in globals() else None),\n",
    "    }\n",
    "\n",
    "if \"rf\" in globals():\n",
    "    results[\"random_forest\"] = {\n",
    "        \"cv_f1_mean\": cv_scores_rf.mean(),\n",
    "        \"cv_f1_std\": cv_scores_rf.std(),\n",
    "        **eval_model(rf, X_test, y_test, le if \"le\" in globals() else None),\n",
    "    }\n",
    "if \"mlp\" in globals():\n",
    "    results[\"mlp\"] = {\n",
    "        \"cv_f1_mean\": cv_scores_mlp.mean(),\n",
    "        \"cv_f1_std\": cv_scores_mlp.std(),\n",
    "        **eval_model(mlp, X_test, y_test, le if \"le\" in globals() else None),\n",
    "    }\n",
    "\n",
    "if \"pipeline\" in globals():  # XGB+SMOTE\n",
    "    results[\"xgb_smote\"] = {\n",
    "        \"cv_f1_mean\": cv_scores.mean(),   # your XGB CV\n",
    "        \"cv_f1_std\": cv_scores.std(),\n",
    "        **eval_model(pipeline, X_test, y_test, le),\n",
    "    }\n",
    "    results[\"selected\"] = \"xgb_smote\"\n",
    "\n",
    "metrics_path = \"../models/metrics.json\"\n",
    "os.makedirs(os.path.dirname(metrics_path), exist_ok=True)\n",
    "with open(metrics_path, \"w\") as f:\n",
    "    json.dump(results, f, indent=2)\n",
    "\n",
    "print(\"Saved metrics to\", metrics_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32ecc1a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save feature list and model for app explanations\n",
    "import joblib, os\n",
    "feature_list_path = \"../models/feature_list.pkl\"\n",
    "model_path = \"../models/trend_model.pkl\"  # reuse existing name\n",
    "os.makedirs(\"../models\", exist_ok=True)\n",
    "joblib.dump(features, feature_list_path)\n",
    "joblib.dump(pipeline, model_path)\n",
    "joblib.dump(le, \"../models/label_encoder.pkl\")\n",
    "\n",
    "print(\"Saved feature list to\", feature_list_path)\n",
    "print(\"Re-saved model to\", model_path)\n",
    "print(\"Feature count:\", len(features))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
